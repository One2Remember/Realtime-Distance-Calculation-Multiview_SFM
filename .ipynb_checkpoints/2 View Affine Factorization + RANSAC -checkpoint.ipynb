{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5c4cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import random\n",
    "from PIL import Image\n",
    "%matplotlib notebook\n",
    "\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4496fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_2659.jpg', 'IMG_2660.jpg']\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"Data\", \"30cm\")\n",
    "\n",
    "image_names = os.listdir(data_path)\n",
    "print(image_names)\n",
    "image_paths = [os.path.join(data_path, image_name) for image_name in image_names]\n",
    "im_array = [(cv.imread(im_path, cv.IMREAD_GRAYSCALE)) for im_path in image_paths]\n",
    "\n",
    "rows, cols = im_array[0].shape\n",
    "div_factor = cols / 400 \n",
    "dims = (int(cols / div_factor), int(rows / div_factor))\n",
    "\n",
    "scaled_im_array = []\n",
    "\n",
    "for i in range(len(im_array)):\n",
    "    scaled_im_array.append(cv.resize(im_array[i], dims, interpolation=cv.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8830a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QR_img_info:\n",
    "    def __init__(self, img, index_george, index_jeff, QR_info, corners):\n",
    "        self.img = img\n",
    "        self.index_george = index_george\n",
    "        self.index_jeff = index_jeff\n",
    "        self.QR_info = QR_info\n",
    "        self.corners = corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ec2e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MATCHES = 50\n",
    "s = 4\n",
    "N_RANSAC = 3000\n",
    "INLIER_THRESHOLD = 0.1\n",
    "\n",
    "# N_MATCHES = 300\n",
    "# s = 4\n",
    "# N_RANSAC = 1000\n",
    "# INLIER_THRESHOLD = 0.5\n",
    "\n",
    "QR_HEIGHT_CM = 5.9\n",
    "GEORGE = 'Robot 1 (George)'\n",
    "JEFF = 'Robot 2 (Jeff)'\n",
    "QR_DIST_CM_TRUE = 30\n",
    "DEBUG = False\n",
    "PLOT_LINE = True\n",
    "DOWNSIZE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12c96e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code for plotting inlier matches between two images\n",
    "def plot_inlier_matches(ax, img1, img2, inliers):\n",
    "    \"\"\"\n",
    "    Plot the matches between two images according to the matched keypoints\n",
    "    :param ax: plot handle\n",
    "    :param img1: left image\n",
    "    :param img2: right image\n",
    "    :inliers: x,y in the first image and x,y in the second image (Nx4)\n",
    "    \"\"\"\n",
    "    res = np.hstack([img1, img2])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.imshow(res, cmap='gray')\n",
    "    \n",
    "    ax.plot(inliers[:,0], inliers[:,1], '+r')\n",
    "    ax.plot(inliers[:,2] + img1.shape[1], inliers[:,3], '+r')\n",
    "    ax.plot([inliers[:,0], inliers[:,2] + img1.shape[1]],\n",
    "            [inliers[:,1], inliers[:,3]], 'r', linewidth=0.4)\n",
    "    ax.axis('off')\n",
    "\n",
    "# constructs matrix A from lecture, projects locations from left image \n",
    "# onto locations in right image\n",
    "def construct_A(l_homo_coords, r_homo_coords):\n",
    "    zero_T = np.zeros(3)\n",
    "    A = np.empty((8,9))\n",
    "    for i in range(s):\n",
    "        x_T = l_homo_coords[i]\n",
    "        row_1 = np.hstack((zero_T, x_T, -1 * r_homo_coords[i][1] * x_T))\n",
    "        row_2 = np.hstack((x_T, zero_T, -1 * r_homo_coords[i][0] * x_T))\n",
    "        A[2*i] = row_1\n",
    "        A[2*i+1] = row_2\n",
    "    return A\n",
    "\n",
    "# convert 2D homogeneous coords to regular 2D coords\n",
    "def homo_to_norm(homo_coords):\n",
    "    return np.array((homo_coords[0] / homo_coords[2], homo_coords[1] / homo_coords[2]))\n",
    "\n",
    "# warp a point using a homography matrix\n",
    "def warp_point(normal_coords, homo_matrix):\n",
    "    # convert coordinates to homogenous coordinates\n",
    "    homo_coords = np.array(normal_coords + (1,))\n",
    "    # compute Hx, projected coordinates of homo_coords\n",
    "    proj_homo_coords = np.matmul(homo_matrix, homo_coords)\n",
    "    # convert projected homo coordinates back to normal coordinates\n",
    "    return homo_to_norm(proj_homo_coords) \n",
    "\n",
    "# compute inliers and avg residuals for given homography\n",
    "def compute_inliers(putatives, l_kps, r_kps, homo_matrix, all_matches):\n",
    "    num_inliers = 0\n",
    "    total_residuals = 0.\n",
    "    inliers = []\n",
    "    # cycle through all putatives for inliers\n",
    "    for i in range(len(putatives)):\n",
    "        # normal coordinates for both points\n",
    "        r_coords = r_kps[all_matches[i].trainIdx].pt\n",
    "        l_coords = l_kps[all_matches[i].queryIdx].pt\n",
    "        # warp point with homography matrix\n",
    "        proj_l_coords = warp_point(l_coords, homo_matrix)\n",
    "        # compute SSD between projected left coords and known right coords\n",
    "        residual = np.sum((r_coords - proj_l_coords)**2)\n",
    "        # if less than threshold, count it\n",
    "        if residual < INLIER_THRESHOLD:\n",
    "            num_inliers += 1\n",
    "            total_residuals += residual\n",
    "            # append inlier as 1D array of length 4 (leftcoords, rightcoords\n",
    "            inliers.append(np.hstack((l_coords, r_coords)))    \n",
    "    return np.array(inliers), total_residuals / num_inliers\n",
    "\n",
    "\n",
    "# RANSAC PARAMETERS\n",
    "def RANSAC(putatives, l_kps, r_kps, all_matches):\n",
    "    # our return values\n",
    "    best_num_inliers = 0\n",
    "    best_avg_inlier_residual = 0\n",
    "    best_homo_matrix = np.empty((3,3))\n",
    "    best_inliers = []\n",
    "    # iterate N_RANSAC times\n",
    "    for i in range(N_RANSAC):\n",
    "        # draw s(4) points at random \n",
    "        matches = random.sample(putatives, s)\n",
    "        # matches are list of elements of form (x1, y1), (x2, y2)\n",
    "        # translate to homogeneous coordinates\n",
    "        coords_left = np.array([np.array(l_kps[matches[i].queryIdx].pt + (1,)) for i in range(s)])\n",
    "        coords_right = np.array([np.array(r_kps[matches[i].trainIdx].pt + (1,)) for i in range(s)])\n",
    "        # construct matrix A as described in lecture\n",
    "        A = construct_A(coords_left, coords_right)\n",
    "        # find solution for homography matrix H\n",
    "        U_, s_, v_ = np.linalg.svd(A)\n",
    "        min_s_val = v_[-1]\n",
    "        homo_matrix = min_s_val.reshape((3,3))\n",
    "        # use H to compute inliers\n",
    "        inliers, avg_residual = compute_inliers(putatives, l_kps, r_kps, homo_matrix, all_matches)\n",
    "        num_inliers = len(inliers)\n",
    "        # update best homography\n",
    "        if num_inliers > best_num_inliers:\n",
    "            best_num_inliers = num_inliers\n",
    "            best_avg_inlier_residual = avg_residual\n",
    "            best_homo_matrix = homo_matrix\n",
    "            best_inliers = inliers\n",
    "    return best_inliers, best_avg_inlier_residual, best_homo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8278a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RANSAC_matrix(img1, img2):\n",
    "    # Initiate ORB detector\n",
    "    orb = cv.ORB_create()\n",
    "    # find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "    # create BFMatcher object\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors.\n",
    "    all_matches = bf.match(des1,des2)\n",
    "    # Sort them in the order of their distance.\n",
    "    all_matches = sorted(all_matches, key = lambda x:x.distance)\n",
    "\n",
    "    if(DEBUG):\n",
    "        # Draw first 10 matches.\n",
    "        img3 = cv.drawMatches(img1,kp1,img2,kp2,all_matches[:50],None)\n",
    "        plt.imshow(img3),plt.show()\n",
    "\n",
    "    putatives = all_matches[:N_MATCHES]\n",
    "    # actual RANSAC calculation\n",
    "    best_inliers, best_avg_inlier_residual, best_homo_matrix = RANSAC(putatives, kp1, kp2, all_matches)\n",
    "\n",
    "    return best_inliers.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7b840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robot_indices(decoded_info):\n",
    "     # find indices of george and jeff QR codes in QR detector responses\n",
    "    index_george, index_jeff = -1, -1\n",
    "    if GEORGE in decoded_info and JEFF in decoded_info:\n",
    "        return decoded_info.index(GEORGE), decoded_info.index(JEFF)\n",
    "    else:\n",
    "        return (-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8a0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract robot QR code info and append to data_matrix (or create data_matrix)\n",
    "def get_full_data_matrix(data_matrix, img_info_1, img_info_2, div_factor):\n",
    "    george_corners_1 = img_info_1.corners[img_info_1.index_george].T\n",
    "    george_corners_2 = img_info_2.corners[img_info_1.index_george].T\n",
    "    jeff_corners_1 = img_info_1.corners[img_info_1.index_jeff].T\n",
    "    jeff_corners_2 = img_info_2.corners[img_info_2.index_jeff].T\n",
    "\n",
    "    george_corners = np.vstack((george_corners_1, george_corners_2))\n",
    "    jeff_corners = np.vstack((jeff_corners_1, jeff_corners_2))\n",
    "\n",
    "    scaled_corners = np.hstack((george_corners, jeff_corners)) / div_factor\n",
    "\n",
    "    # return coordinates stacked with data_matrix\n",
    "    if data_matrix != []:\n",
    "        return np.hstack((data_matrix, scaled_corners)) \n",
    "    else: # just the scaled corners\n",
    "        return scaled_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014b8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the matrix Q to eliminate the affine ambiguity using the method described on slide 32 of the lecture.\n",
    "takes: and M from \n",
    "\"\"\"\n",
    "def get_3d_reconstruction(data_matrix):\n",
    "    means = np.mean(data_matrix, axis=1, keepdims=True)\n",
    "    norm_matrix = data_matrix - means\n",
    "\n",
    "    m2, n = norm_matrix.shape\n",
    "    m = m2 // 2\n",
    "\n",
    "    if(DEBUG):\n",
    "        print(\"m: \" + str(m))\n",
    "        print(\"n: \" + str(n))\n",
    "\n",
    "    \"\"\"\n",
    "    Apply SVD to the 2M x N data matrix to express it as D = U @ W @ V' \n",
    "    (using NumPy notation) where U is a 2Mx3 matrix, W is a 3x3 matrix \n",
    "    of the top three singular values, and V is a Nx3 matrix. \n",
    "    Next, derive structure and motion matrices from the SVD\n",
    "    \"\"\"\n",
    "    U, W, V_T = np.linalg.svd(norm_matrix)\n",
    "    U_3 = U[:,:3]\n",
    "    SIGMA_3 = np.diag(W[:3])\n",
    "    VT_3 = V_T[:3]\n",
    "\n",
    "    M = U_3 @ np.sqrt(SIGMA_3)\n",
    "    S = np.sqrt(SIGMA_3) @ VT_3\n",
    "    \n",
    "    coeff = np.empty((4*m,6))\n",
    "    vec = np.empty((4*m))\n",
    "    for i in range(m):\n",
    "        A = M[2*i:2*i+2]\n",
    "        A11 = A[0][0]\n",
    "        A12 = A[0][1]\n",
    "        A13 = A[0][2]\n",
    "        A21 = A[1][0]\n",
    "        A22 = A[1][1]\n",
    "        A23 = A[1][2]\n",
    "        coeff[4*i]   = np.array([A11*A11, A11*A12, A11*A13, A12*A12, A12*A13, A13*A13])\n",
    "        coeff[4*i+1] = np.array([A21*A11, A21*A12, A21*A13, A22*A12, A22*A13, A23*A13])\n",
    "        coeff[4*i+2] = np.array([A11*A21, A11*A22, A11*A23, A12*A22, A12*A23, A13*A23])\n",
    "        coeff[4*i+3] = np.array([A21*A21, A21*A22, A21*A23, A22*A22, A22*A23, A23*A23])\n",
    "        vec[4*i]   = 1\n",
    "        vec[4*i+1] = 0\n",
    "        vec[4*i+2] = 0\n",
    "        vec[4*i+3] = 1  \n",
    "\n",
    "    x, residuals, rank, s = np.linalg.lstsq(coeff, vec)\n",
    "    L = np.array([[x[0], x[1], x[2]], [x[1], x[3], x[4]], [x[2], x[4], x[5]]])\n",
    "    Q = np.linalg.cholesky(L)\n",
    "    MQ = M@Q\n",
    "    QS = np.linalg.inv(Q)@S\n",
    "    D = MQ@QS\n",
    "    D_trans = D + means\n",
    "    \n",
    "    if(DEBUG):\n",
    "        print(\"L:\")\n",
    "        print(L)\n",
    "        print(\"Q:\")\n",
    "        print(Q)\n",
    "    \n",
    "    return MQ, QS, D_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9422964",
   "metadata": {},
   "source": [
    "Use matplotlib to display the 3D structure (in your report, you may want to include snapshots from several viewpoints to show the structure clearly). Discuss whether or not the reconstruction has an ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7f3f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance between two QR codes given 3D coordinate array QS\n",
    "def get_distance_and_centers(QS):\n",
    "    # create sequences of corners for each shape (repeating the first corner again at the end)\n",
    "    square_1 = np.c_[QS[:,-8:-4], QS[:,-8]]\n",
    "    square_2 = np.c_[QS[:,-4:], QS[:,-4]]\n",
    "\n",
    "    square_1_perimeter = 0\n",
    "    square_2_perimeter = 0\n",
    "\n",
    "    # loop through all pairs of corners to calculate total square perimeters\n",
    "    for i in range(4):\n",
    "        square_1_perimeter += np.linalg.norm(square_1[:,i]-square_1[:,i+1])\n",
    "        square_2_perimeter += np.linalg.norm(square_2[:,i]-square_2[:,i+1])\n",
    "\n",
    "    average_side_length = (square_1_perimeter + square_2_perimeter) / 8\n",
    "\n",
    "    # calculate ratio of 3d distances to real world distance\n",
    "    # now, we can use this to measure distances, take any distance in 3d and divide by this ratio to get CM\n",
    "    ratio_3d_real = average_side_length / QR_HEIGHT_CM\n",
    "\n",
    "    # now we calculate the center of both squares in 3d\n",
    "    center_1 = np.mean(QS[:,-8:-4], axis=1)\n",
    "    center_2 = np.mean(QS[:,-4:], axis=1)\n",
    "\n",
    "    center_line = (center_1 + center_2) / 2\n",
    "\n",
    "    distance_3d = np.linalg.norm(center_1-center_2)\n",
    "\n",
    "    distance_real = distance_3d / ratio_3d_real\n",
    "    \n",
    "\n",
    "    print(\"Calculated 3-D Distance between squares in cm: \" + str(distance_real))\n",
    "    print(\"True 3-D distance between squares in cm: \" + str(QR_DIST_CM_TRUE))\n",
    "    \n",
    "    if(PLOT_LINE):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        ax.scatter(QS[0][:-8], QS[1][:-8], QS[2][:-8])\n",
    "        ax.scatter(QS[0][-8:-4], QS[1][-8:-4], QS[2][-8:-4], marker='o')\n",
    "        ax.scatter(QS[0][-4:], QS[1][-4:], QS[2][-4:], marker='^')\n",
    "\n",
    "        ax.plot([center_1[0], center_2[0]], [center_1[1], center_2[1]], [center_1[2], center_2[2]], marker = 'p', color='red')\n",
    "        ax.text(center_line[0], center_line[1], center_line[2], \"{:.2f}\".format(distance_real) + \"cm\")\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        plt.show()\n",
    "        \n",
    "    return distance_real, center_1, center_2, center_line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c819015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALIBRATED\n",
      "GOT FIRST IMAGE 2\n",
      "CALCULATING DISTANCE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dista\\AppData\\Local\\Temp\\ipykernel_7532\\2139039277.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if data_matrix != []:\n",
      "C:\\Users\\dista\\AppData\\Local\\Temp\\ipykernel_7532\\94683563.py:49: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  x, residuals, rank, s = np.linalg.lstsq(coeff, vec)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Matrix is not positive definite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m data_matrix \u001b[38;5;241m=\u001b[39m get_full_data_matrix(data_matrix, img_info_1, img_info_2, div_factor)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# perform 3d reconstruction from data_matrix\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m MQ, QS, D_trans \u001b[38;5;241m=\u001b[39m \u001b[43mget_3d_reconstruction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# calculate real world distances\u001b[39;00m\n\u001b[0;32m     64\u001b[0m distance_real, center_1, center_2, center_line \u001b[38;5;241m=\u001b[39m get_distance_and_centers(QS)\n",
      "Cell \u001b[1;32mIn [9], line 51\u001b[0m, in \u001b[0;36mget_3d_reconstruction\u001b[1;34m(data_matrix)\u001b[0m\n\u001b[0;32m     49\u001b[0m x, residuals, rank, s \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mlstsq(coeff, vec)\n\u001b[0;32m     50\u001b[0m L \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m], x[\u001b[38;5;241m2\u001b[39m]], [x[\u001b[38;5;241m1\u001b[39m], x[\u001b[38;5;241m3\u001b[39m], x[\u001b[38;5;241m4\u001b[39m]], [x[\u001b[38;5;241m2\u001b[39m], x[\u001b[38;5;241m4\u001b[39m], x[\u001b[38;5;241m5\u001b[39m]]])\n\u001b[1;32m---> 51\u001b[0m Q \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m MQ \u001b[38;5;241m=\u001b[39m M\u001b[38;5;129m@Q\u001b[39m\n\u001b[0;32m     53\u001b[0m QS \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(Q)\u001b[38;5;129m@S\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\numpy\\linalg\\linalg.py:770\u001b[0m, in \u001b[0;36mcholesky\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    768\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n\u001b[0;32m    769\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 770\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(r\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pythonProject\\lib\\site-packages\\numpy\\linalg\\linalg.py:92\u001b[0m, in \u001b[0;36m_raise_linalgerror_nonposdef\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_nonposdef\u001b[39m(err, flag):\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrix is not positive definite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Matrix is not positive definite"
     ]
    }
   ],
   "source": [
    "camera_id_0 = 0\n",
    "camera_id_0 = 1\n",
    "delay = 1\n",
    "window_name = 'OpenCV QR Code'\n",
    "\n",
    "qcd = cv.QRCodeDetector()\n",
    "cap1 = cv.VideoCapture(camera_id_0)\n",
    "cap2 = cv.VideoCapture(camera_id_1)\n",
    "\n",
    "img_1_shape = ()\n",
    "\n",
    "img_info_1 = []\n",
    "img_info_2 = []\n",
    "\n",
    "webcams_calibrated = False\n",
    "while webcams_calibrated == False:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if ret1 and ret2:\n",
    "        img_1_shape = frame1.shape\n",
    "        img_2_shape = frame2.shape\n",
    "        \n",
    "        print(img_1_shape)\n",
    "        print(img_2_shape)\n",
    "        \n",
    "#         img = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "#         ret, decoded_info, corners, straight_qrcode = qcd.detectAndDecodeMulti(img)\n",
    "#         index_george, index_jeff = get_robot_indices(decoded_info)\n",
    "#         if index_george != -1 and index_jeff != -1:\n",
    "#             webcam_calibrated = True\n",
    "#             img_info_1 = QR_img_info(img, index_george, index_jeff, decoded_info, corners)\n",
    "#             print(\"CALIBRATED\")\n",
    "\n",
    "# while True:\n",
    "#     # ret is whether image was read\n",
    "#     # frame is image\n",
    "#     ret, frame = cap.read()\n",
    "    \n",
    "#     if ret:\n",
    "#         # if we don't have a valid second image, just continue\n",
    "#         temp_img = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "#         ret, decoded_info, corners, straight_qrcode = qcd.detectAndDecodeMulti(temp_img)\n",
    "#         index_george, index_jeff = get_robot_indices(decoded_info)\n",
    "#         if index_george == -1 or index_jeff == -1:\n",
    "\n",
    "#             continue\n",
    "#         # set our two img_infos\n",
    "#         if(img_info_2 == []):\n",
    "#             img_info_2 = QR_img_info(temp_img, index_george, index_jeff, decoded_info, corners)\n",
    "#             print(\"GOT FIRST IMAGE 2\")\n",
    "#         else:\n",
    "#             img_info_1, img_info_2 = img_info_2, QR_img_info(temp_img, index_george, index_jeff, decoded_info, corners)\n",
    "        \n",
    "#         if(DOWNSIZE):\n",
    "#             rows, cols = img_shape\n",
    "#             div_factor = cols / 400 \n",
    "#             dims = (int(cols / div_factor), int(rows / div_factor))\n",
    "#             img_info_1.img = cv.resize(img_info_1.img, dims, interpolation=cv.INTER_AREA)\n",
    "#             img_info_2.img = cv.resize(img_info_2.img, dims, interpolation=cv.INTER_AREA)\n",
    "        \n",
    "#         print(\"CALCULATING DISTANCE\")\n",
    "#         # calculate data matrix\n",
    "#         data_matrix = []\n",
    "#         # first perform RANSAC if applicable\n",
    "#         if(RANSAC):\n",
    "#             data_matrix = get_RANSAC_matrix(img_info_1.img, img_info_2.img)\n",
    "#         # then append QR coordinates\n",
    "#         data_matrix = get_full_data_matrix(data_matrix, img_info_1, img_info_2, div_factor)\n",
    "#         # perform 3d reconstruction from data_matrix\n",
    "#         MQ, QS, D_trans = get_3d_reconstruction(data_matrix)\n",
    "#         # calculate real world distances\n",
    "#         distance_real, center_1, center_2, center_line = get_distance_and_centers(QS)\n",
    "\n",
    "    if cv.waitKey(delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661fb364",
   "metadata": {},
   "source": [
    "Display three frames with both the observed feature points and the estimated projected 3D points overlayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4614cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ct = 0\n",
    "# for i in [0,1]:\n",
    "#     xs = data_matrix[2*i]\n",
    "#     ys = data_matrix[2*i+1]\n",
    "    \n",
    "#     x_projs = D_trans[2*i]\n",
    "#     y_projs = D_trans[2*i+1]\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot()\n",
    "#     ax.scatter(xs, ys, marker='o')\n",
    "#     ax.scatter(x_projs, y_projs, marker='^')\n",
    "#     ax.set_xlabel('X')\n",
    "#     ax.set_ylabel('Y')\n",
    "    \n",
    "#     plt.imshow(scaled_im_array[ct],cmap='gray')\n",
    "#     ct+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0331fbb4",
   "metadata": {},
   "source": [
    "Report your total residual (sum of squared Euclidean distances, in pixels, between the observed and the reprojected features) over all the frames, and plot the per-frame residual as a function of the frame number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b984393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals = np.empty((m))\n",
    "# for i in range(m):\n",
    "#     coords = data_matrix[2*i:2*i+2]\n",
    "#     proj_coords = D_trans[2*i:2*i+2]\n",
    "    \n",
    "#     residuals[i] = np.sum(np.linalg.norm(coords-proj_coords)**2, axis=0)\n",
    "    \n",
    "# total_residual = np.sum(residuals)\n",
    "\n",
    "# xs = np.array([i for i in range(1, m+1)])\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot()\n",
    "# ax.set_xlabel('Frame')\n",
    "# ax.set_ylabel('Residual')\n",
    "# ax.plot(xs, residuals)\n",
    "\n",
    "# print(total_residual)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f736cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568bb53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
