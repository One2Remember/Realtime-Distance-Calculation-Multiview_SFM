{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5c4cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import random\n",
    "from PIL import Image\n",
    "%matplotlib notebook\n",
    "\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4496fed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_2660.jpg', 'IMG_2659.jpg']\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), \"Data\", \"30cm\")\n",
    "\n",
    "image_names = os.listdir(data_path)\n",
    "print(image_names)\n",
    "image_paths = [os.path.join(data_path, image_name) for image_name in image_names]\n",
    "im_array = [(cv.imread(im_path, cv.IMREAD_GRAYSCALE)) for im_path in image_paths]\n",
    "\n",
    "rows, cols = im_array[0].shape\n",
    "div_factor = cols / 400 \n",
    "dims = (int(cols / div_factor), int(rows / div_factor))\n",
    "\n",
    "scaled_im_array = []\n",
    "\n",
    "for i in range(len(im_array)):\n",
    "    scaled_im_array.append(cv.resize(im_array[i], dims, interpolation=cv.INTER_AREA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8830a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QR_img_info:\n",
    "    def __init__(self, img, index_george, index_jeff, QR_info, corners):\n",
    "        self.img = img\n",
    "        self.index_george = index_george\n",
    "        self.index_jeff = index_jeff\n",
    "        self.QR_info = QR_info\n",
    "        self.corners = corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ec2e2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MATCHES = 50\n",
    "s = 4\n",
    "N_RANSAC = 3000\n",
    "INLIER_THRESHOLD = 0.1\n",
    "\n",
    "# N_MATCHES = 300\n",
    "# s = 4\n",
    "# N_RANSAC = 1000\n",
    "# INLIER_THRESHOLD = 0.5\n",
    "\n",
    "QR_HEIGHT_CM = 11.7\n",
    "GEORGE = 'Robot 1 (George)'\n",
    "JEFF = 'Robot 2 (Jeff)'\n",
    "QR_DIST_CM_TRUE = 30\n",
    "DEBUG = False\n",
    "PLOT_LINE = True\n",
    "DOWNSIZE = False\n",
    "RANSAC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c96e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided code for plotting inlier matches between two images\n",
    "def plot_inlier_matches(ax, img1, img2, inliers):\n",
    "    \"\"\"\n",
    "    Plot the matches between two images according to the matched keypoints\n",
    "    :param ax: plot handle\n",
    "    :param img1: left image\n",
    "    :param img2: right image\n",
    "    :inliers: x,y in the first image and x,y in the second image (Nx4)\n",
    "    \"\"\"\n",
    "    res = np.hstack([img1, img2])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.imshow(res, cmap='gray')\n",
    "    \n",
    "    ax.plot(inliers[:,0], inliers[:,1], '+r')\n",
    "    ax.plot(inliers[:,2] + img1.shape[1], inliers[:,3], '+r')\n",
    "    ax.plot([inliers[:,0], inliers[:,2] + img1.shape[1]],\n",
    "            [inliers[:,1], inliers[:,3]], 'r', linewidth=0.4)\n",
    "    ax.axis('off')\n",
    "\n",
    "# constructs matrix A from lecture, projects locations from left image \n",
    "# onto locations in right image\n",
    "def construct_A(l_homo_coords, r_homo_coords):\n",
    "    zero_T = np.zeros(3)\n",
    "    A = np.empty((8,9))\n",
    "    for i in range(s):\n",
    "        x_T = l_homo_coords[i]\n",
    "        row_1 = np.hstack((zero_T, x_T, -1 * r_homo_coords[i][1] * x_T))\n",
    "        row_2 = np.hstack((x_T, zero_T, -1 * r_homo_coords[i][0] * x_T))\n",
    "        A[2*i] = row_1\n",
    "        A[2*i+1] = row_2\n",
    "    return A\n",
    "\n",
    "# convert 2D homogeneous coords to regular 2D coords\n",
    "def homo_to_norm(homo_coords):\n",
    "    return np.array((homo_coords[0] / homo_coords[2], homo_coords[1] / homo_coords[2]))\n",
    "\n",
    "# warp a point using a homography matrix\n",
    "def warp_point(normal_coords, homo_matrix):\n",
    "    # convert coordinates to homogenous coordinates\n",
    "    homo_coords = np.array(normal_coords + (1,))\n",
    "    # compute Hx, projected coordinates of homo_coords\n",
    "    proj_homo_coords = np.matmul(homo_matrix, homo_coords)\n",
    "    # convert projected homo coordinates back to normal coordinates\n",
    "    return homo_to_norm(proj_homo_coords) \n",
    "\n",
    "# compute inliers and avg residuals for given homography\n",
    "def compute_inliers(putatives, l_kps, r_kps, homo_matrix, all_matches):\n",
    "    num_inliers = 0\n",
    "    total_residuals = 0.\n",
    "    inliers = []\n",
    "    # cycle through all putatives for inliers\n",
    "    for i in range(len(putatives)):\n",
    "        # normal coordinates for both points\n",
    "        r_coords = r_kps[all_matches[i].trainIdx].pt\n",
    "        l_coords = l_kps[all_matches[i].queryIdx].pt\n",
    "        # warp point with homography matrix\n",
    "        proj_l_coords = warp_point(l_coords, homo_matrix)\n",
    "        # compute SSD between projected left coords and known right coords\n",
    "        residual = np.sum((r_coords - proj_l_coords)**2)\n",
    "        # if less than threshold, count it\n",
    "        if residual < INLIER_THRESHOLD:\n",
    "            num_inliers += 1\n",
    "            total_residuals += residual\n",
    "            # append inlier as 1D array of length 4 (leftcoords, rightcoords\n",
    "            inliers.append(np.hstack((l_coords, r_coords)))    \n",
    "    return np.array(inliers), total_residuals / num_inliers\n",
    "\n",
    "\n",
    "# RANSAC PARAMETERS\n",
    "def RANSAC(putatives, l_kps, r_kps, all_matches):\n",
    "    # our return values\n",
    "    best_num_inliers = 0\n",
    "    best_avg_inlier_residual = 0\n",
    "    best_homo_matrix = np.empty((3,3))\n",
    "    best_inliers = []\n",
    "    # iterate N_RANSAC times\n",
    "    for i in range(N_RANSAC):\n",
    "        # draw s(4) points at random \n",
    "        matches = random.sample(putatives, s)\n",
    "        # matches are list of elements of form (x1, y1), (x2, y2)\n",
    "        # translate to homogeneous coordinates\n",
    "        coords_left = np.array([np.array(l_kps[matches[i].queryIdx].pt + (1,)) for i in range(s)])\n",
    "        coords_right = np.array([np.array(r_kps[matches[i].trainIdx].pt + (1,)) for i in range(s)])\n",
    "        # construct matrix A as described in lecture\n",
    "        A = construct_A(coords_left, coords_right)\n",
    "        # find solution for homography matrix H\n",
    "        U_, s_, v_ = np.linalg.svd(A)\n",
    "        min_s_val = v_[-1]\n",
    "        homo_matrix = min_s_val.reshape((3,3))\n",
    "        # use H to compute inliers\n",
    "        inliers, avg_residual = compute_inliers(putatives, l_kps, r_kps, homo_matrix, all_matches)\n",
    "        num_inliers = len(inliers)\n",
    "        # update best homography\n",
    "        if num_inliers > best_num_inliers:\n",
    "            best_num_inliers = num_inliers\n",
    "            best_avg_inlier_residual = avg_residual\n",
    "            best_homo_matrix = homo_matrix\n",
    "            best_inliers = inliers\n",
    "    return best_inliers, best_avg_inlier_residual, best_homo_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e8278a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RANSAC_matrix(img1, img2):\n",
    "    # Initiate ORB detector\n",
    "    orb = cv.ORB_create()\n",
    "    # find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "    # create BFMatcher object\n",
    "    bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors.\n",
    "    all_matches = bf.match(des1,des2)\n",
    "    # Sort them in the order of their distance.\n",
    "    all_matches = sorted(all_matches, key = lambda x:x.distance)\n",
    "\n",
    "    if(DEBUG):\n",
    "        # Draw first 10 matches.\n",
    "        img3 = cv.drawMatches(img1,kp1,img2,kp2,all_matches[:50],None)\n",
    "        plt.imshow(img3),plt.show()\n",
    "\n",
    "    putatives = all_matches[:N_MATCHES]\n",
    "    # actual RANSAC calculation\n",
    "    best_inliers, best_avg_inlier_residual, best_homo_matrix = RANSAC(putatives, kp1, kp2, all_matches)\n",
    "\n",
    "    return best_inliers.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b7b840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robot_indices(decoded_info):\n",
    "     # find indices of george and jeff QR codes in QR detector responses\n",
    "    index_george, index_jeff = -1, -1\n",
    "    if GEORGE in decoded_info and JEFF in decoded_info:\n",
    "        return decoded_info.index(GEORGE), decoded_info.index(JEFF)\n",
    "    else:\n",
    "        return (-1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d8a0118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract robot QR code info and append to data_matrix (or create data_matrix)\n",
    "def get_full_data_matrix(data_matrix, img_info_1, img_info_2, div_factor):\n",
    "    george_corners_1 = img_info_1.corners[img_info_1.index_george].T\n",
    "    george_corners_2 = img_info_2.corners[img_info_1.index_george].T\n",
    "    jeff_corners_1 = img_info_1.corners[img_info_1.index_jeff].T\n",
    "    jeff_corners_2 = img_info_2.corners[img_info_2.index_jeff].T\n",
    "\n",
    "    george_corners = np.vstack((george_corners_1, george_corners_2))\n",
    "    jeff_corners = np.vstack((jeff_corners_1, jeff_corners_2))\n",
    "\n",
    "    scaled_corners = np.hstack((george_corners, jeff_corners)) / div_factor\n",
    "\n",
    "    # return coordinates stacked with data_matrix\n",
    "    if data_matrix != []:\n",
    "        return np.hstack((data_matrix, scaled_corners)) \n",
    "    else: # just the scaled corners\n",
    "        return scaled_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "014b8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the matrix Q to eliminate the affine ambiguity using the method described on slide 32 of the lecture.\n",
    "takes: and M from \n",
    "\"\"\"\n",
    "def get_3d_reconstruction(data_matrix):\n",
    "    means = np.mean(data_matrix, axis=1, keepdims=True)\n",
    "    norm_matrix = data_matrix - means\n",
    "\n",
    "    m2, n = norm_matrix.shape\n",
    "    m = m2 // 2\n",
    "\n",
    "    if(DEBUG):\n",
    "        print(\"m: \" + str(m))\n",
    "        print(\"n: \" + str(n))\n",
    "\n",
    "    \"\"\"\n",
    "    Apply SVD to the 2M x N data matrix to express it as D = U @ W @ V' \n",
    "    (using NumPy notation) where U is a 2Mx3 matrix, W is a 3x3 matrix \n",
    "    of the top three singular values, and V is a Nx3 matrix. \n",
    "    Next, derive structure and motion matrices from the SVD\n",
    "    \"\"\"\n",
    "    U, W, V_T = np.linalg.svd(norm_matrix)\n",
    "    U_3 = U[:,:3]\n",
    "    SIGMA_3 = np.diag(W[:3])\n",
    "    VT_3 = V_T[:3]\n",
    "\n",
    "    M = U_3 @ np.sqrt(SIGMA_3)\n",
    "    S = np.sqrt(SIGMA_3) @ VT_3\n",
    "    \n",
    "    coeff = np.empty((4*m,6))\n",
    "    vec = np.empty((4*m))\n",
    "    for i in range(m):\n",
    "        A = M[2*i:2*i+2]\n",
    "        A11 = A[0][0]\n",
    "        A12 = A[0][1]\n",
    "        A13 = A[0][2]\n",
    "        A21 = A[1][0]\n",
    "        A22 = A[1][1]\n",
    "        A23 = A[1][2]\n",
    "        coeff[4*i]   = np.array([A11*A11, A11*A12, A11*A13, A12*A12, A12*A13, A13*A13])\n",
    "        coeff[4*i+1] = np.array([A21*A11, A21*A12, A21*A13, A22*A12, A22*A13, A23*A13])\n",
    "        coeff[4*i+2] = np.array([A11*A21, A11*A22, A11*A23, A12*A22, A12*A23, A13*A23])\n",
    "        coeff[4*i+3] = np.array([A21*A21, A21*A22, A21*A23, A22*A22, A22*A23, A23*A23])\n",
    "        vec[4*i]   = 1\n",
    "        vec[4*i+1] = 0\n",
    "        vec[4*i+2] = 0\n",
    "        vec[4*i+3] = 1  \n",
    "\n",
    "    x, residuals, rank, s = np.linalg.lstsq(coeff, vec)\n",
    "    L = np.array([[x[0], x[1], x[2]], [x[1], x[3], x[4]], [x[2], x[4], x[5]]])\n",
    "    Q = np.linalg.cholesky(L)\n",
    "    MQ = M@Q\n",
    "    QS = np.linalg.inv(Q)@S\n",
    "    D = MQ@QS\n",
    "    D_trans = D + means\n",
    "    \n",
    "    if(DEBUG):\n",
    "        print(\"L:\")\n",
    "        print(L)\n",
    "        print(\"Q:\")\n",
    "        print(Q)\n",
    "    \n",
    "    return MQ, QS, D_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9422964",
   "metadata": {},
   "source": [
    "Use matplotlib to display the 3D structure (in your report, you may want to include snapshots from several viewpoints to show the structure clearly). Discuss whether or not the reconstruction has an ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7f3f82b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (729115873.py, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [20], line 45\u001b[0;36m\u001b[0m\n\u001b[0;31m    ax.text(.05, .5, .05, 'runtime: '+str(round(runtime, 2)+'s')\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# calculate distance between two QR codes given 3D coordinate array QS\n",
    "def get_distance_and_centers(QS, counter, start_time):\n",
    "    # create sequences of corners for each shape (repeating the first corner again at the end)\n",
    "    square_1 = np.c_[QS[:,-8:-4], QS[:,-8]]\n",
    "    square_2 = np.c_[QS[:,-4:], QS[:,-4]]\n",
    "\n",
    "    square_1_perimeter = 0\n",
    "    square_2_perimeter = 0\n",
    "\n",
    "    # loop through all pairs of corners to calculate total square perimeters\n",
    "    for i in range(4):\n",
    "        square_1_perimeter += np.linalg.norm(square_1[:,i]-square_1[:,i+1])\n",
    "        square_2_perimeter += np.linalg.norm(square_2[:,i]-square_2[:,i+1])\n",
    "\n",
    "    average_side_length = (square_1_perimeter + square_2_perimeter) / 8\n",
    "\n",
    "    # calculate ratio of 3d distances to real world distance\n",
    "    # now, we can use this to measure distances, take any distance in 3d and divide by this ratio to get CM\n",
    "    ratio_3d_real = average_side_length / QR_HEIGHT_CM\n",
    "\n",
    "    # now we calculate the center of both squares in 3d\n",
    "    center_1 = np.mean(QS[:,-8:-4], axis=1)\n",
    "    center_2 = np.mean(QS[:,-4:], axis=1)\n",
    "\n",
    "    center_line = (center_1 + center_2) / 2\n",
    "\n",
    "    distance_3d = np.linalg.norm(center_1-center_2)\n",
    "\n",
    "    distance_real = distance_3d / ratio_3d_real\n",
    "    runtime = time.time() - start_time\n",
    "    \n",
    "\n",
    "    print(\"Calculated 3-D Distance between squares in cm: \" + str(distance_real))\n",
    "    print(\"True 3-D distance between squares in cm: \" + str(QR_DIST_CM_TRUE))\n",
    "    \n",
    "    if(PLOT_LINE):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection='3d')\n",
    "        ax.scatter(QS[0][:-8], QS[1][:-8], QS[2][:-8])\n",
    "        ax.scatter(QS[0][-8:-4], QS[1][-8:-4], QS[2][-8:-4], marker='o')\n",
    "        ax.scatter(QS[0][-4:], QS[1][-4:], QS[2][-4:], marker='^')\n",
    "\n",
    "        ax.plot([center_1[0], center_2[0]], [center_1[1], center_2[1]], [center_1[2], center_2[2]], marker = 'p', color='red')\n",
    "        ax.text(center_line[0], center_line[1], center_line[2], \"{:.2f}\".format(distance_real) + \"cm\")\n",
    "        ax.text(.05, .5, .05, 'runtime: '+str(round(runtime, 2)+'s')\n",
    "\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_title('3D reconstruction RANSAC')\n",
    "        plt.savefig('ransac_' + str(counter))\n",
    "        \n",
    "    return distance_real, center_1, center_2, center_line\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c819015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n",
      "Got one image\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#         print(\"got both frames\")\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#         cv.imshow(\"image1\", frame1)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#         cv.imshow(\"image2\", frame2)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         cv\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr_frame1_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(success_count)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, frame1)\n\u001b[0;32m---> 29\u001b[0m         \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr_frame2_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msuccess_count\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m         img_1 \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mcvtColor(frame1, cv\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     32\u001b[0m         ret_1, decoded_info_1, corners_1, straight_qrcode_1 \u001b[38;5;241m=\u001b[39m qcd\u001b[38;5;241m.\u001b[39mdetectAndDecodeMulti(img_1)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "camera_id_0 = 0\n",
    "camera_id_1 = 1\n",
    "delay = 1\n",
    "window_name = 'OpenCV QR Code'\n",
    "\n",
    "qcd = cv.QRCodeDetector()\n",
    "cap1 = cv.VideoCapture(camera_id_0)\n",
    "cap2 = cv.VideoCapture(camera_id_1)\n",
    "\n",
    "img_1_shape = ()\n",
    "\n",
    "img_info_1 = []\n",
    "img_info_2 = []\n",
    "\n",
    "\n",
    "success_count = 0\n",
    "while success_count < 10:\n",
    "    ret1, frame1 = cap1.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if ret1 and ret2:\n",
    "        img_1_shape = frame1.shape\n",
    "        img_2_shape = frame2.shape        \n",
    "#         print(\"got both frames\")\n",
    "        \n",
    "#         cv.imshow(\"image1\", frame1)\n",
    "#         cv.imshow(\"image2\", frame2)\n",
    "        \n",
    "        img_1 = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "        ret_1, decoded_info_1, corners_1, straight_qrcode_1 = qcd.detectAndDecodeMulti(img_1)\n",
    "        index_george_1, index_jeff_1 = get_robot_indices(decoded_info_1)\n",
    "        if index_george_1 != -1 and index_jeff_1 != -1:\n",
    "            print(\"Got one image\")\n",
    "            img_2 = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "            ret_2, decoded_info_2, corners_2, straight_qrcode_2 = qcd.detectAndDecodeMulti(img_2)\n",
    "            index_george_2, index_jeff_2 = get_robot_indices(decoded_info_2)\n",
    "            if index_george_2 != -1 and index_jeff_2 != -1:\n",
    "                img_info_1 = QR_img_info(img_1, index_george_1, index_jeff_1, decoded_info_1, corners_1)\n",
    "                img_info_2 = QR_img_info(img_2, index_george_2, index_jeff_2, decoded_info_2, corners_2)\n",
    "                print(\"Got two images\")\n",
    "                cv.imwrite('r_frame1_'+str(success_count)+'.jpg', frame1)\n",
    "                cv.imwrite(\"r_frame2_\"+str(success_count)+'.jpg', frame2)\n",
    "                \n",
    "                if(DOWNSIZE):\n",
    "                    rows, cols = img_shape\n",
    "                    div_factor = cols / 400 \n",
    "                    dims = (int(cols / div_factor), int(rows / div_factor))\n",
    "                    img_info_1.img = cv.resize(img_info_1.img, dims, interpolation=cv.INTER_AREA)\n",
    "                    img_info_2.img = cv.resize(img_info_2.img, dims, interpolation=cv.INTER_AREA)\n",
    "                \n",
    "                try:\n",
    "                    print(\"CALCULATING DISTANCE\")\n",
    "                    start_time = time.time()\n",
    "                    # calculate data matrix\n",
    "                    data_matrix = []\n",
    "                    # first perform RANSAC if applicable\n",
    "                    if(RANSAC):\n",
    "                        data_matrix = get_RANSAC_matrix(img_info_1.img, img_info_2.img)\n",
    "                    # then append QR coordinates\n",
    "                    data_matrix = get_full_data_matrix(data_matrix, img_info_1, img_info_2, div_factor)\n",
    "                    # perform 3d reconstruction from data_matrix\n",
    "                    MQ, QS, D_trans = get_3d_reconstruction(data_matrix)\n",
    "\n",
    "                    # calculate real world distances\n",
    "                    distance_real, center_1, center_2, center_line = get_distance_and_centers(QS, success_count, start_time)\n",
    "                    success_count += 1\n",
    "                    print(\"count:\", success_count)\n",
    "                except Exception as e:\n",
    "                    print(\"err\", str(e))\n",
    "                    continue\n",
    "\n",
    "    if cv.waitKey(delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f736cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870ca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
